{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.164105Z",
     "start_time": "2021-08-23T15:45:00.905814Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.277839Z",
     "start_time": "2021-08-23T15:45:01.165138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stability_diversity_full.csv\tstability.h5\r\n",
      "stability_diversity_test.csv\tstability_test.csv\r\n",
      "stability_diversity_train.csv\tstability_test.h5\r\n",
      "stability_embeddings_test.pkl\tstability_train.csv\r\n",
      "stability_embeddings_train.pkl\tstability_train.h5\r\n",
      "stability_embeddings_val.pkl\r\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('data')\n",
    "\n",
    "!ls $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.322241Z",
     "start_time": "2021-08-23T15:45:01.285454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>consensus_stability_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSSQETIEVEDEEEARRVAKELRKKGYEVKDERRGNKWHVHRT</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLDEARELVERAKKEGTGMDVNGQRFEDWREAERWVREQEKNK</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELKKKLEEALKKGEEVRVKFNGIEIRNTSEDAARKAVELLEK</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSSQETIEVEDEEEARRVAKELRKTGYEVKIERRGNKWHVHRT</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTIHVGDLTLKYDNPKKAYEIAKKLAKKYNLQVTIKNGKITVT</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>GSSKTQYEYDTKEEHQKAYEKFKKQGIPVTITQKNGKWFVQVE</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>TIDEIIKALEQAVKDNKPIQVGNYTVTSADEAEKLAKKLKKPY</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7707</th>\n",
       "      <td>TQDEIIKALEQAVKDNKPIQVGNYTVTSADEAEKLAKKLKKEY</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>TTIKVNGQEYTVPLSPEQAAKAAKKRWPDYEVQIHGNTVWVTR</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>GSSTTWYRFTDEEEARRAAKEWARRGYQVHVTQNGTYWEVEVR</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7710 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sequence  consensus_stability_score\n",
       "0     GSSQETIEVEDEEEARRVAKELRKKGYEVKDERRGNKWHVHRT                       0.37\n",
       "1     TLDEARELVERAKKEGTGMDVNGQRFEDWREAERWVREQEKNK                       0.62\n",
       "2     TELKKKLEEALKKGEEVRVKFNGIEIRNTSEDAARKAVELLEK                      -0.03\n",
       "3     GSSQETIEVEDEEEARRVAKELRKTGYEVKIERRGNKWHVHRT                       1.41\n",
       "4     TTIHVGDLTLKYDNPKKAYEIAKKLAKKYNLQVTIKNGKITVT                       1.11\n",
       "...                                           ...                        ...\n",
       "7705  GSSKTQYEYDTKEEHQKAYEKFKKQGIPVTITQKNGKWFVQVE                       0.80\n",
       "7706  TIDEIIKALEQAVKDNKPIQVGNYTVTSADEAEKLAKKLKKPY                       0.82\n",
       "7707  TQDEIIKALEQAVKDNKPIQVGNYTVTSADEAEKLAKKLKKEY                       0.66\n",
       "7708  TTIKVNGQEYTVPLSPEQAAKAAKKRWPDYEVQIHGNTVWVTR                       1.05\n",
       "7709  GSSTTWYRFTDEEEARRAAKEWARRGYQVHVTQNGTYWEVEVR                       1.69\n",
       "\n",
       "[7710 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def open_sets(base_path):\n",
    "    sets = {}\n",
    "\n",
    "    for path in base_path.glob('*.csv'):\n",
    "        fname = path.stem\n",
    "        kind = fname.split('_')[1]\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        sets[kind] = df\n",
    "        \n",
    "    return sets\n",
    "\n",
    "sets = open_sets(data_path)\n",
    "sets['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.327136Z",
     "start_time": "2021-08-23T15:45:01.323417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sets['train']['sequence'].unique()) != len(sets['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.391031Z",
     "start_time": "2021-08-23T15:45:01.328340Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5222d98641a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0malignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalxx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0malignment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "\n",
    "alignment = pairwise2.align.globalxx(sets['train']['sequence'][0], sets['train']['sequence'][1])\n",
    "print(pairwise2.format_alignment(*alignment[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score per metrics\n",
    "\n",
    "* More unique values => more stability?\n",
    "* Does sequence lenght matter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.392113Z",
     "start_time": "2021-08-23T15:45:00.914Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_key(d, k, v):\n",
    "    if k in d:\n",
    "        values = d[k]\n",
    "        values.append(v)\n",
    "        d[k] = values\n",
    "        \n",
    "    else:\n",
    "        d[k] = [v]\n",
    "        \n",
    "def compute_mean_scores(d):\n",
    "    new_d = dict()\n",
    "    for k in d:\n",
    "        mean_score = np.mean(d[k])\n",
    "        new_d[k] = (mean_score, len(d[k]))\n",
    "        \n",
    "    return  OrderedDict(sorted(new_d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.392677Z",
     "start_time": "2021-08-23T15:45:00.915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_per_length = dict()\n",
    "score_per_uniqueness = dict()\n",
    "\n",
    "for idx, (seq, score) in sets['train'].iterrows():\n",
    "    # score_per_length\n",
    "    size = len(seq)\n",
    "    append_to_key(score_per_length, size, score)\n",
    "    \n",
    "    \n",
    "    # score_per_uniqueness\n",
    "    uniques = set(seq)\n",
    "    uniq_size = len(uniques)\n",
    "    \n",
    "    append_to_key(score_per_uniqueness, uniq_size, score)\n",
    "    \n",
    "    # count unique aminoacids\n",
    "    for amino in uniques:\n",
    "        uniques.add(amino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.393180Z",
     "start_time": "2021-08-23T15:45:00.916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_mean_scores(score_per_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.393728Z",
     "start_time": "2021-08-23T15:45:00.917Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_mean_scores(score_per_uniqueness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.394210Z",
     "start_time": "2021-08-23T15:45:00.919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_train = sets['train'].sort_values(by='consensus_stability_score').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.394675Z",
     "start_time": "2021-08-23T15:45:00.920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignment = pairwise2.align.globalxx(sorted_train['sequence'][0], sorted_train['sequence'][1])\n",
    "print(pairwise2.format_alignment(*alignment[0]))\n",
    "\n",
    "sorted_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.395165Z",
     "start_time": "2021-08-23T15:45:00.922Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignment = pairwise2.align.globalxx(\n",
    "    sorted_train['sequence'][len(sorted_train)-1], \n",
    "    sorted_train['sequence'][len(sorted_train)-2]\n",
    ")\n",
    "\n",
    "print(pairwise2.format_alignment(*alignment[0]))\n",
    "\n",
    "sorted_train.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Diversity Maximizing: This is a greedy strategy which starts from the reference and adds the sequence with highest average hamming distance to current set of sequences.\n",
    "\n",
    "* Diversity Minimizing: This strategy is equivalent to the Diversity Maximizing strategy, but adds the se- quence with lowest average hamming distance. It is used to explore the effects of diversity on model per- formance.\n",
    "\n",
    "* HHFilter: This strategy applies hhfilter (Steinegger etal.,2019)withthe-diff Mparameter,whichre- turns M or more sequences that maximize diversity (the result is usually close to M). If more than M sequences are returned we apply the Diversity Maxi- mizing strategy on top of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T15:45:01.395705Z",
     "start_time": "2021-08-23T15:45:00.923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignment[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T16:38:40.066967Z",
     "start_time": "2021-08-23T16:38:39.993713Z"
    },
    "code_folding": [
     62
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def compute_diversity(seq1, seq2, method = \"hamming\"):\n",
    "    if method == \"alignment\":\n",
    "        method = pairwise2.align.globalxx\n",
    "        diversity = method(seq1, seq2)\n",
    "        diversity = diversity[0].score / max(len(seq1), len(seq2))\n",
    "        \n",
    "    elif method == \"hamming\":\n",
    "        if len(seq1) != len(seq2):\n",
    "            return np.nan\n",
    "        \n",
    "        method = distance.hamming\n",
    "        diversity = method(list(seq1), list(seq2))\n",
    "        \n",
    "    return diversity\n",
    "\n",
    "\n",
    "def dataset_diversity(sequences, method = \"hamming\", reduce = \"mean\", verbose = True):\n",
    "    if reduce != \"mean\":\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        # nan results are due to different lengths\n",
    "        reducer = np.nanmean\n",
    "    \n",
    "    reduced_divs = []\n",
    "    if verbose: \n",
    "        pbar = tqdm(total = len(sequences), miniters = 1, smoothing = 1)\n",
    "\n",
    "    for seq_idx, seq in enumerate(sequences):\n",
    "        other_sequences = np.concatenate((sequences[:seq_idx] , sequences[seq_idx + 1:]))\n",
    "        \n",
    "        if seq in other_sequences:\n",
    "            raise IndexError(f\"{seq_idx} is in other_sequences, e.g. it is not correctly indexed\")\n",
    "        \n",
    "\n",
    "        v_diversity = np.vectorize(lambda x: compute_diversity(seq, x))\n",
    "        if len(other_sequences) > 1:\n",
    "            div_vs_all = v_diversity(other_sequences)  \n",
    "        else:\n",
    "            print(f\"Skipping sequence {seq_idx}\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        reduced_div_vs_all = reducer(div_vs_all) if len(div_vs_all) >= 1 else np.nan\n",
    "        reduced_divs.append(reduced_div_vs_all)\n",
    "        \n",
    "        if verbose:\n",
    "            pbar.update(1)\n",
    "            pbar.refresh()\n",
    "    \n",
    "    if verbose:\n",
    "        pbar.close()\n",
    "        \n",
    "    return reduced_divs\n",
    "\n",
    "def sample_by_diversity(sequences, size, min_score = 0.7, args = {\"verbose\" : False}):\n",
    "    check_diversity = lambda ds : np.nanmean(dataset_diversity(np.array(list(ds)), **args)) >= min_score\n",
    "    \n",
    "    sampled_seqs = set()\n",
    "    max_iters = 10\n",
    "    current_iters = 0\n",
    "    while len(sampled_seqs) < size:\n",
    "        idx_sample = random.sample(range(len(sequences)), 1)\n",
    "        sample = sequences[idx_sample]\n",
    "        \n",
    "        is_empty = len(sampled_seqs) == 0 or len(sampled_seqs) == 1\n",
    "        \n",
    "        if is_empty or check_diversity(sampled_seqs.union({sample[0]})):\n",
    "            sampled_seqs.add(sample[0])\n",
    "            sequences = np.delete(sequences, idx_sample)\n",
    "            if len(sampled_seqs) % (size // 10) == 0:\n",
    "                print(len(sampled_seqs))\n",
    "            \n",
    "        else: \n",
    "            continue\n",
    "    # check diversity\n",
    "    if not check_diversity(sampled_seqs):\n",
    "        raise ValueError(\"Sampled diversity error\")\n",
    "        \n",
    "    return sampled_seqs\n",
    "\n",
    "def select_by_diversity(sequences, diversities, min_size, min_score = 0.7, args = {\"verbose\" : False}):\n",
    "    chosen_seqs = []\n",
    "    \n",
    "    min_diversity = lambda ds : np.nanmean(dataset_diversity(np.array(list(ds)), **args)) >= min_score\n",
    "    diminishes_diversity = lambda idx: diversities[idx] > min_size\n",
    "    around_size = lambda seqs: len(seqs) * 1.2 >= min_size\n",
    "    is_empty = len(chosen_seqs) == 0 or len(chosen_seqs) == 1\n",
    "    \n",
    "\n",
    "    with tqdm(total = min_size, miniters = 10, smoothing = 1) as pbar:\n",
    "        last_diversity = False\n",
    "        while len(chosen_seqs) <= min_size:\n",
    "            max_iters = 10\n",
    "            current_iters = 0\n",
    "\n",
    "            seq_set = set(chosen_seqs).union({sequences[0]}) \n",
    "        \n",
    "            if is_empty or not diminishes_diversity(0) or min_diversity(seq_set):\n",
    "                chosen_seqs.append(sequences[0])\n",
    "                sequences = np.delete(sequences, 0)\n",
    "                diversities = np.delete(diversities, 0)\n",
    "\n",
    "                current_iters = 0\n",
    "            pbar.update(1)\n",
    "\n",
    "            if current_iters >= max_iters:\n",
    "                break\n",
    "            else:\n",
    "                current_iters += 1\n",
    "\n",
    "            if diminishes_diversity(0) and min_diversity(seq_set) and around_size(chosen_seqs):\n",
    "                break\n",
    "            \n",
    "    return chosen_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T16:54:45.658872Z",
     "start_time": "2021-08-23T16:38:40.598720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bff79a2ccc4195bad1608dee4c0b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diversities_train = dataset_diversity(sets[\"train\"][\"sequence\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T17:19:34.394711Z",
     "start_time": "2021-08-23T17:19:34.392025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8394134005304014,\n",
       " 0.8469666259574454,\n",
       " 0.8795092981365058,\n",
       " 0.83650682658194,\n",
       " 0.8295142928034904,\n",
       " 0.8158611289236332,\n",
       " 0.836996626183011,\n",
       " 0.043124059151686885,\n",
       " 0.8282833490692195,\n",
       " 0.87912583660672]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversities_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T17:19:39.244504Z",
     "start_time": "2021-08-23T17:19:39.232208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>consensus_stability_score</th>\n",
       "      <th>diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSSQETIEVEDEEEARRVAKELRKKGYEVKDERRGNKWHVHRT</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.839413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLDEARELVERAKKEGTGMDVNGQRFEDWREAERWVREQEKNK</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.846967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELKKKLEEALKKGEEVRVKFNGIEIRNTSEDAARKAVELLEK</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.879509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSSQETIEVEDEEEARRVAKELRKTGYEVKIERRGNKWHVHRT</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.836507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTIHVGDLTLKYDNPKKAYEIAKKLAKKYNLQVTIKNGKITVT</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.829514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SKDEAQREAERAIRSGNKEEARRILEEVGYSPEQAERIIRKLG</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.815861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TIDEIIKALEQAVKDGKPIQVGNYTVTSADEAEKLAKKLKKEY</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.836997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FEIPDDVPLPAGWEMARTSSGQRYFKNHIDQTTTWQDPRKAMLSQM</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.043124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TTIHVGDLTLKYDNPKKAYEIAKKLDKKYNLTVTIKNGKITVT</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GSSGSLSDEDFKAVFGMTRSAFAMLPLWKQQNLKKEKGLFGSS</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.879126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sequence  consensus_stability_score  \\\n",
       "0     GSSQETIEVEDEEEARRVAKELRKKGYEVKDERRGNKWHVHRT                       0.37   \n",
       "1     TLDEARELVERAKKEGTGMDVNGQRFEDWREAERWVREQEKNK                       0.62   \n",
       "2     TELKKKLEEALKKGEEVRVKFNGIEIRNTSEDAARKAVELLEK                      -0.03   \n",
       "3     GSSQETIEVEDEEEARRVAKELRKTGYEVKIERRGNKWHVHRT                       1.41   \n",
       "4     TTIHVGDLTLKYDNPKKAYEIAKKLAKKYNLQVTIKNGKITVT                       1.11   \n",
       "5     SKDEAQREAERAIRSGNKEEARRILEEVGYSPEQAERIIRKLG                       1.24   \n",
       "6     TIDEIIKALEQAVKDGKPIQVGNYTVTSADEAEKLAKKLKKEY                       1.05   \n",
       "7  FEIPDDVPLPAGWEMARTSSGQRYFKNHIDQTTTWQDPRKAMLSQM                       0.89   \n",
       "8     TTIHVGDLTLKYDNPKKAYEIAKKLDKKYNLTVTIKNGKITVT                       0.88   \n",
       "9     GSSGSLSDEDFKAVFGMTRSAFAMLPLWKQQNLKKEKGLFGSS                       1.15   \n",
       "\n",
       "   diversity  \n",
       "0   0.839413  \n",
       "1   0.846967  \n",
       "2   0.879509  \n",
       "3   0.836507  \n",
       "4   0.829514  \n",
       "5   0.815861  \n",
       "6   0.836997  \n",
       "7   0.043124  \n",
       "8   0.828283  \n",
       "9   0.879126  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/stability_diversity_train.csv\", index_col=0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T21:30:51.057222Z",
     "start_time": "2021-08-02T21:30:51.055760Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ds_div_train = dataset_diversity(sets[\"train\"][\"sequence\"])\n",
    "# sets[\"train\"][\"diversity\"] = np.nanmean(np.array(ds_div_train), 1)\n",
    "# np.nanmean(np.array(ds_div_train))\n",
    "# 0.8xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T21:30:51.466948Z",
     "start_time": "2021-08-02T21:30:51.465766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ds_div_test = dataset_diversity(sets[\"test\"][\"sequence\"])\n",
    "# sets[\"test\"][\"diversity\"] = np.nanmean(np.array(ds_div_test), 1)\n",
    "# np.nanmean(np.array(ds_div_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T21:30:51.878164Z",
     "start_time": "2021-08-02T21:30:51.876794Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sets[\"train\"].to_csv(f\"{data_path}/stability_diversity_train.csv\")\n",
    "# sets[\"test\"].to_csv(f\"{data_path}/stability_diversity_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T21:30:52.500119Z",
     "start_time": "2021-08-02T21:30:52.489687Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = {\n",
    "    'train' : pd.read_csv(f\"{data_path}/stability_diversity_train.csv\"),\n",
    "    'test'  : pd.read_csv(f\"{data_path}/stability_diversity_test.csv\") \n",
    "}\n",
    "\n",
    "sorted_div = {\n",
    "    \"train\" : sets[\"train\"].sort_values(by=\"diversity\", axis=0, ascending=False),\n",
    "    \"test\"  : sets[\"test\"].sort_values(by=\"diversity\", axis=0, ascending=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:49:13.157977Z",
     "start_time": "2021-08-16T17:49:13.154484Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ProteinStabilityDataset(Dataset):\n",
    "    \"\"\"Protein1D Stability dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, proteins_path, ret_dict = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proteins_path (string): Path to the H5Py file that contains sequences and embeddings.\n",
    "        \"\"\"\n",
    "        self.stability_path = proteins_path\n",
    "        self.ret_dict = ret_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(h5py.File(self.stability_path, \"r\")['sequences'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        with h5py.File(self.stability_path, \"r\") as dset:\n",
    "            sequences = dset['sequences'][idx]\n",
    "            embeddings = dset['embeddings'][idx]\n",
    "            labels = dset['labels'][idx]\n",
    "            \n",
    "            sample = {\n",
    "                'sequences': sequences, \n",
    "                'embeddings': torch.from_numpy(embeddings), \n",
    "                'labels': torch.Tensor([labels])\n",
    "            }\n",
    "\n",
    "        return sample if self.ret_dict else (sample['embeddings'], sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:49:13.507131Z",
     "start_time": "2021-08-16T17:49:13.501302Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler, DataLoader, SubsetRandomSampler\n",
    "from typing import List, Sized, Iterator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class SubsetDiversitySampler(Sampler):\n",
    "    \"\"\"Samples elements given their diversity w.r.t. the rest of the dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset: Sized, diversity_path : str, diversity_cutoff : float, strategy : str = \"maximize\", seed : int = 123) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          diversity_path (string): Path to the csv with sequences and diversity.\n",
    "        \"\"\"\n",
    "        self.diversity_path = diversity_path\n",
    "        self.diversity_data = pd.read_csv(self.diversity_path, index_col=0)\n",
    "        \n",
    "        if strategy == \"maximize\":\n",
    "            sorting_order = False\n",
    "        elif strategy == \"minimize\":\n",
    "            sorting_order = True\n",
    "        else: \n",
    "            raise ValueError(f\"Strategy {strategy} is not supported\")\n",
    "        \n",
    "        self.diversity_data = self.diversity_data.sort_values(\n",
    "            by='diversity', \n",
    "            ascending=sorting_order\n",
    "        )\n",
    "        \n",
    "        self.cutoff = diversity_cutoff\n",
    "        self.indices = []\n",
    "        self.strategy = strategy\n",
    "        self.seed = seed\n",
    "        \n",
    "        if strategy == 'maximize':\n",
    "            self.cutoff_lambda = lambda x, cutoff : x < cutoff\n",
    "        elif strategy == 'minimize':\n",
    "            self.cutoff_lambda = lambda x, cutoff : x > cutoff\n",
    "            \n",
    "        self.subset_by_cutoff(self.cutoff, self.cutoff_lambda)\n",
    "            \n",
    "    def subset_by_cutoff(self, cutoff, cutoff_func) -> None:\n",
    "        for row in self.diversity_data.itertuples():\n",
    "            is_cutoff = cutoff_func(row.diversity, cutoff)\n",
    "            if is_cutoff:\n",
    "                break\n",
    "            else:\n",
    "                self.indices.append(row.Index)\n",
    "        \n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        return iter(rng.permutation(self.indices))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:50:56.320721Z",
     "start_time": "2021-08-16T17:50:53.033183Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = ProteinStabilityDataset(\"data/stability.h5\", ret_dict=True)\n",
    "sampler = SubsetDiversitySampler(dataset, \"data/stability_diversity_full.csv\", 0.85)\n",
    "dl = DataLoader(dataset, batch_size=128, sampler=sampler)\n",
    "\n",
    "# check diversity sampler\n",
    "df = pd.read_csv(\"data/stability_diversity_full.csv\", index_col=0)\n",
    "for batch in dl:\n",
    "    for seq in batch[\"sequences\"]:\n",
    "        row = df[df.sequence == str(seq, 'utf-8')]\n",
    "        if float(row.diversity.values) < 0.85:\n",
    "            raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:47:49.121409Z",
     "start_time": "2021-08-16T17:47:49.119786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for s in [1000, 1500, 2000, 3000, 4000, 5000, 6000]:\n",
    "#     for kind in [\"train\"]:\n",
    "#         chosen_by_diversity = select_by_diversity(\n",
    "#             sequences=sorted_div[kind][\"sequence\"].values, \n",
    "#             diversities=sorted_div[kind][\"diversity\"].values,\n",
    "#             min_size=s, \n",
    "#             min_score=0.78\n",
    "#         )\n",
    "    \n",
    "#     subset = sets[\"train\"][sets[\"train\"][\"sequence\"].isin(chosen_by_diversity)]\n",
    "#     subset.to_csv(f\"{data_path}/stability_diversity_train_{s}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stability",
   "language": "python",
   "name": "stability"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
